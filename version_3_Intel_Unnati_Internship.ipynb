{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "yePs4XIIV85C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "#Student model\n",
        "class lightweightstudentCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(lightweightstudentCNN,self).__init__()\n",
        "    self.encoder=nn.Sequential(\n",
        "        nn.Conv2d(3,16,kernel_size=3,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(16,32,kernel_size=3,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "    self.middle=nn.Sequential(\n",
        "        nn.Conv2d(32,32,kernel_size=3,padding=1),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.decoder=nn.Sequential(\n",
        "        nn.Upsample(scale_factor=2,mode=\"bilinear\",align_corners=False),\n",
        "        nn.Conv2d(32,16,kernel_size=3,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(16,3,kernel_size=3,padding=1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self,x):\n",
        "      x=self.encoder(x)\n",
        "      x=self.middle(x)\n",
        "      x=self.decoder(x)\n",
        "      return x\n",
        "#Custom Dataset\n",
        "class ImagePairDataset(Dataset):\n",
        "  def __init__(self,blurred,groundtruth,transform=None):\n",
        "    self.blurred_paths=sorted([os.path.join(blurred,f) for f in os.listdir(blurred) if f.endswith(('.png','.jpg'))])\n",
        "    self.groundtruth_paths=sorted([os.path.join(groundtruth,f) for f in os.listdir(groundtruth) if f.endswith(('.png','.jpg'))])\n",
        "    self.transform=transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.blurred_paths)\n",
        "\n",
        "  def pad_to_multiple(self,image,m=16):\n",
        "    width,height=image.size\n",
        "    new_width=(width+m-1)//m*m\n",
        "    new_height=(height+m-1)//m*m\n",
        "    return image.resize((new_width,new_height))\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    blur=Image.open(self.blurred_paths[idx]).convert(\"RGB\")\n",
        "    gt=Image.open(self.groundtruth_paths[idx]).convert(\"RGB\")\n",
        "    blur=self.pad_to_multiple(blur,m=16)\n",
        "    gt=self.pad_to_multiple(gt,m=16)\n",
        "\n",
        "    if self.transform:\n",
        "      blur=self.transform(blur)\n",
        "      gt=self.transform(gt)\n",
        "    return blur,gt,os.path.basename(self.blurred_paths[idx])\n",
        "   #Distillation training\n",
        "def trainingCNN(blurred,groundtruth,teacher_model,epochs=10,batch_size=32,lr=1e-4):\n",
        "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    transform=transforms.Compose([\n",
        "        transforms.Resize((256,480)),\n",
        "        transforms.ToTensor()\n",
        "        ])\n",
        "    data=ImagePairDataset(blurred,groundtruth,transform=transform)\n",
        "    dataloader=DataLoader(data,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "    teacher_model.to(device)\n",
        "    teacher_model.eval()\n",
        "\n",
        "    studentmodel=lightweightstudentCNN().to(device)\n",
        "    optimizer=optim.Adam(studentmodel.parameters(),lr=lr)\n",
        "    criteria=nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      studentmodel.train()\n",
        "      epoch_loss=0.0\n",
        "      for blur,gt,_ in dataloader:\n",
        "        blur,gt=blur.to(device),gt.to(device)\n",
        "        with torch.no_grad():\n",
        "          teacher_output=teacher_model(blur)\n",
        "        student_output=studentmodel(blur)\n",
        "        loss=distillation_loss(student_output,teacher_output,gt,alpha=0.5,beta=0.3,g=0.2)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss=epoch_loss+loss.item()\n",
        "        torch.cuda.empty_cache()\n",
        "      print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(dataloader)}\")\n",
        "    torch.save(studentmodel.state_dict(),\"student_model.pth\")\n",
        "\n",
        "\n",
        "#Inference+SSIM Evaluation\n",
        "def restore_and_evaluate(student_model,blurred,groundtruth):\n",
        "  device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  transform=transforms.Compose([\n",
        "      transforms.Resize((1080,1920)),\n",
        "      transforms.ToTensor()\n",
        "  ])\n",
        "  data=ImagePairDataset(blurred,groundtruth,transform=transform)\n",
        "  dataloader=DataLoader(data,batch_size=1,shuffle=False)\n",
        "\n",
        "  model=lightweightstudentCNN().to(device)\n",
        "  model.load_state_dict(torch.load(student_model,map_location=device))\n",
        "  model.eval()\n",
        "\n",
        "  ssim_scores=[]\n",
        "  os.makedirs(\"restored_images\",exist_ok=True)\n",
        "\n",
        "  for blur,gt,filename in dataloader:\n",
        "    blur,gt=blur.to(device),gt.to(device)\n",
        "    with torch.no_grad():\n",
        "      output=model(blur)\n",
        "\n",
        "    output_n=output.squeeze(0).permute(1,2,0).cpu().numpy()\n",
        "    gt_n=gt.squeeze(0).permute(1,2,0).cpu().numpy()\n",
        "\n",
        "\n",
        "    output_n = np.clip(output_n * 255, 0, 255).astype(np.uint8)\n",
        "    gt_n = np.clip(gt_n * 255, 0, 255).astype(np.uint8)\n",
        "\n",
        "\n",
        "    #save images\n",
        "    output_image_path=os.path.join(\"restored_images\",filename[0])\n",
        "    Image.fromarray(output_n).save(output_image_path)\n",
        "\n",
        "    #ssim\n",
        "    score=ssim(output_n,gt_n,data_range=255,channel_axis=2)\n",
        "    ssim_scores.append(score)\n",
        "    print(f\"SSIM for {filename[0]}:{score:.4f}\")\n",
        "\n",
        "  print(f\"\\nAverage SSIM:{np.mean(ssim_scores):.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install einops\n",
        "\n",
        "if os.path.isdir('Restormer'):\n",
        "  !rm -r Restormer\n",
        "\n",
        "# Clone Restormer\n",
        "!git clone https://github.com/swz30/Restormer.git\n",
        "%cd Restormer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Px35Qe-yhWZ",
        "outputId": "0e863307-34e5-433e-9d44-e82ffd38f299"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Cloning into 'Restormer'...\n",
            "remote: Enumerating objects: 309, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 309 (delta 67), reused 56 (delta 56), pack-reused 202 (from 1)\u001b[K\n",
            "Receiving objects: 100% (309/309), 1.56 MiB | 10.30 MiB/s, done.\n",
            "Resolving deltas: 100% (123/123), done.\n",
            "/content/Restormer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# task = 'Real_Denoising'\n",
        "# task = 'Single_Image_Defocus_Deblurring'\n",
        "task = 'Motion_Deblurring'\n",
        "# task = 'Deraining'\n",
        "\n",
        "# Download the pre-trained models\n",
        "if task is 'Real_Denoising':\n",
        "  !wget https://github.com/swz30/Restormer/releases/download/v1.0/real_denoising.pth -P Denoising/pretrained_models\n",
        "if task is 'Single_Image_Defocus_Deblurring':\n",
        "  !wget https://github.com/swz30/Restormer/releases/download/v1.0/single_image_defocus_deblurring.pth -P Defocus_Deblurring/pretrained_models\n",
        "if task is 'Motion_Deblurring':\n",
        "  !wget https://github.com/swz30/Restormer/releases/download/v1.0/motion_deblurring.pth -P Motion_Deblurring/pretrained_models\n",
        "if task is 'Deraining':\n",
        "  !wget https://github.com/swz30/Restormer/releases/download/v1.0/deraining.pth -P Deraining/pretrained_models\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn7flMnUypCg",
        "outputId": "096fa575-9463-498a-c60d-cc2a465e141f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "/tmp/ipython-input-5-1693683666.py:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if task is 'Real_Denoising':\n",
            "/tmp/ipython-input-5-1693683666.py:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if task is 'Single_Image_Defocus_Deblurring':\n",
            "/tmp/ipython-input-5-1693683666.py:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if task is 'Motion_Deblurring':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-11 04:52:24--  https://github.com/swz30/Restormer/releases/download/v1.0/motion_deblurring.pth\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/418793252/55c7bcd2-cb39-4d8a-adc4-acf6f6131c27?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250711%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250711T045224Z&X-Amz-Expires=1800&X-Amz-Signature=a3db011f3f518b03a234694232aba66fc7d0e10a17c8a2c6e9504d60f2fabd7d&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmotion_deblurring.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-07-11 04:52:24--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/418793252/55c7bcd2-cb39-4d8a-adc4-acf6f6131c27?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250711%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250711T045224Z&X-Amz-Expires=1800&X-Amz-Signature=a3db011f3f518b03a234694232aba66fc7d0e10a17c8a2c6e9504d60f2fabd7d&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmotion_deblurring.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 104700429 (100M) [application/octet-stream]\n",
            "Saving to: ‘Motion_Deblurring/pretrained_models/motion_deblurring.pth’\n",
            "\n",
            "motion_deblurring.p 100%[===================>]  99.85M   287MB/s    in 0.3s    \n",
            "\n",
            "2025-07-11 04:52:25 (287 MB/s) - ‘Motion_Deblurring/pretrained_models/motion_deblurring.pth’ saved [104700429/104700429]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-5-1693683666.py:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if task is 'Deraining':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from runpy import run_path\n",
        "\n",
        "#Load Restormer Architecture\n",
        "restormer_path=os.path.join(\"basicsr\",\"models\",\"archs\",\"restormer_arch.py\")\n",
        "restormer_arch=run_path(restormer_path)\n",
        "restormer=restormer_arch['Restormer']\n",
        "\n",
        "#Define Model Parameters (match traininf config)\n",
        "teacher_params={\n",
        "    'inp_channels':3,\n",
        "    'out_channels':3,\n",
        "    'dim':48,\n",
        "    'num_blocks':[4,6,6,8],\n",
        "    'num_refinement_blocks':4,\n",
        "    'heads':[1,2,4,8],\n",
        "    'ffn_expansion_factor':2.66,\n",
        "    'bias':False,\n",
        "    'LayerNorm_type':'WithBias',\n",
        "    'dual_pixel_task':False\n",
        "}\n",
        "\n",
        "#Load the pretrained model\n",
        "restormer_model=restormer(**teacher_params)\n",
        "ckpt_path=os.path.join(\"Motion_Deblurring\",\"pretrained_models\",\"motion_deblurring.pth\")\n",
        "checkpoint=torch.load(ckpt_path,map_location=\"cpu\")\n",
        "restormer_model.load_state_dict(checkpoint['params'])\n",
        "restormer_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbq1hnCGytIQ",
        "outputId": "f02b2480-6ccd-4924-ca6e-bfd7760e9832",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Restormer(\n",
              "  (patch_embed): OverlapPatchEmbed(\n",
              "    (proj): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  )\n",
              "  (encoder_level1): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
              "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
              "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
              "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
              "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down1_2): Downsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelUnshuffle(downscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (encoder_level2): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down2_3): Downsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelUnshuffle(downscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (encoder_level3): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down3_4): Downsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelUnshuffle(downscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (latent): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up4_3): Upsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelShuffle(upscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (reduce_chan_level3): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (decoder_level3): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up3_2): Upsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelShuffle(upscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (reduce_chan_level2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (decoder_level2): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up2_1): Upsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelShuffle(upscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (decoder_level1): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (refinement): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (output): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_msssim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EkqvSzrJr3Ih",
        "outputId": "3377e99b-d1d0-4b02-b1f8-566cd0080648"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_msssim\n",
            "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pytorch_msssim) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->pytorch_msssim)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->pytorch_msssim)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->pytorch_msssim)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->pytorch_msssim)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->pytorch_msssim)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->pytorch_msssim)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->pytorch_msssim)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->pytorch_msssim)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->pytorch_msssim)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->pytorch_msssim)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->pytorch_msssim) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->pytorch_msssim) (3.0.2)\n",
            "Downloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m128.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch_msssim\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch_msssim-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from pytorch_msssim import ssim as torch_ssim\n",
        "from torchvision import models\n",
        "\n",
        "vg=models.vgg16(pretrained=True).features.eval()\n",
        "for param in vg.parameters():\n",
        "  param.requires_grad=False\n",
        "\n",
        "# Move VGG to the correct device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vg.to(device)\n",
        "\n",
        "layers=[3,8,15]\n",
        "\n",
        "def extract_features(a,model,layers):\n",
        "  features=[]\n",
        "  for i,layer in enumerate(model):\n",
        "      a=layer(a)\n",
        "      if i in layers:\n",
        "        features.append(a)\n",
        "  return features\n",
        "\n",
        "def distillation_loss(student_out,teacher_out,ground_truth,alpha=0.5,beta=0.3,g=0.2):\n",
        "  l1_loss=F.l1_loss(student_out,ground_truth)\n",
        "  ssim_loss=1-torch_ssim(student_out,ground_truth,data_range=1.0)\n",
        "  student_feats=extract_features(student_out,vg,layers)\n",
        "  teacher_feats=extract_features(teacher_out,vg,layers)\n",
        "  p_loss=sum( F.mse_loss(s,t) for s,t in zip(student_feats,teacher_feats))\n",
        "  feature_loss=F.mse_loss(student_feats[-1],teacher_feats[-1])\n",
        "  return(alpha*l1_loss+beta*ssim_loss+g*p_loss+0.1*feature_loss)"
      ],
      "metadata": {
        "id": "2oHtxeNG3euE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf45e1fe-23af-45b7-c3aa-e4979ed13c74"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blur=\"/content/blurred_5200_0_6.zip\"\n",
        "gt=\"/content/numpysliced_5200.zip\""
      ],
      "metadata": {
        "id": "KGuq5wX74Ere"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "#Extract ZIP files\n",
        "def extract_zip(zip_path,extract_to):\n",
        "  os.makedirs(extract_to,exist_ok=True)\n",
        "  with zipfile.ZipFile(zip_path,\"r\") as zip_ref:\n",
        "     zip_ref.extractall(extract_to)\n",
        "  #return extract_to\n",
        "\n",
        "blur_folder=extract_zip(\"/content/blurred_5200_0_6.zip\",\"blur_extracted\")\n",
        "gt_folder=extract_zip(\"/content/numpysliced_5200.zip\",\"gt_extracted\")\n",
        "\n"
      ],
      "metadata": {
        "id": "a_uF1Rwg4T8Y",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Ensure teacher model is on the correct device\n",
        "teacher_model = restormer_model.to(device)  # ✅ This ensures compatibility with GPU input\n",
        "\n",
        "# Later you already have:\n",
        "studentmodel = lightweightstudentCNN().to(device)\n"
      ],
      "metadata": {
        "id": "BBrz-559zq2r"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingCNN(\"/content/Restormer/blur_extracted\",\"/content/Restormer/gt_extracted\",teacher_model=restormer_model,batch_size=16)"
      ],
      "metadata": {
        "id": "II-PiLx8C1i-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de7723b3-f263-485d-9993-d20f37ebcdb9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.35737027493806983\n",
            "Epoch 2/10, Loss: 0.16759135823983412\n",
            "Epoch 3/10, Loss: 0.12452336146281316\n",
            "Epoch 4/10, Loss: 0.09366513424194776\n",
            "Epoch 5/10, Loss: 0.0864768362733034\n",
            "Epoch 6/10, Loss: 0.08267088286005533\n",
            "Epoch 7/10, Loss: 0.07986932713251847\n",
            "Epoch 8/10, Loss: 0.07791924828520189\n",
            "Epoch 9/10, Loss: 0.07624424122847044\n",
            "Epoch 10/10, Loss: 0.07465646537450643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "def extract_zip(zip_path, extract_to):\n",
        "    os.makedirs(extract_to, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    return extract_to"
      ],
      "metadata": {
        "id": "N7E-sNmkY_PV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=extract_zip(\"/content/new_valid.zip\",\"/content/gt1_valid\")\n",
        "y=extract_zip(\"/content/new_blur_valid.zip\",\"/content/blur1_valid\")"
      ],
      "metadata": {
        "id": "sew-g0JkZJJV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restore_and_evaluate(\"/content/Restormer/student_model.pth\",y,x)"
      ],
      "metadata": {
        "id": "NTF85WLOzeRW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d2fba5a-ba8a-4507-a5ec-bb1e89f460b9",
        "collapsed": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SSIM for 0801.png:0.9272\n",
            "SSIM for 0802.png:0.8643\n",
            "SSIM for 0803.png:0.9548\n",
            "SSIM for 0804.png:0.8810\n",
            "SSIM for 0805.png:0.9006\n",
            "SSIM for 0806.png:0.8965\n",
            "SSIM for 0807.png:0.7193\n",
            "SSIM for 0808.png:0.8776\n",
            "SSIM for 0809.png:0.9375\n",
            "SSIM for 0810.png:0.8970\n",
            "SSIM for 0811.png:0.9048\n",
            "SSIM for 0812.png:0.8995\n",
            "SSIM for 0813.png:0.9146\n",
            "SSIM for 0814.png:0.9425\n",
            "SSIM for 0815.png:0.9439\n",
            "SSIM for 0816.png:0.9276\n",
            "SSIM for 0817.png:0.9070\n",
            "SSIM for 0818.png:0.9227\n",
            "SSIM for 0819.png:0.9004\n",
            "SSIM for 0820.png:0.8800\n",
            "SSIM for 0821.png:0.8853\n",
            "SSIM for 0822.png:0.9127\n",
            "SSIM for 0823.png:0.8966\n",
            "SSIM for 0824.png:0.9302\n",
            "SSIM for 0825.png:0.9001\n",
            "SSIM for 0826.png:0.8522\n",
            "SSIM for 0827.png:0.9325\n",
            "SSIM for 0828.png:0.7106\n",
            "SSIM for 0829.png:0.8201\n",
            "SSIM for 0830.png:0.8784\n",
            "SSIM for 0831.png:0.9125\n",
            "SSIM for 0832.png:0.9241\n",
            "SSIM for 0833.png:0.9399\n",
            "SSIM for 0834.png:0.8854\n",
            "SSIM for 0835.png:0.8070\n",
            "SSIM for 0836.png:0.8674\n",
            "SSIM for 0837.png:0.8901\n",
            "SSIM for 0838.png:0.9557\n",
            "SSIM for 0839.png:0.9320\n",
            "SSIM for 0840.png:0.9101\n",
            "SSIM for 0841.png:0.9262\n",
            "SSIM for 0842.png:0.9328\n",
            "SSIM for 0843.png:0.9863\n",
            "SSIM for 0844.png:0.9794\n",
            "SSIM for 0845.png:0.8640\n",
            "SSIM for 0846.png:0.8721\n",
            "SSIM for 0847.png:0.8779\n",
            "SSIM for 0848.png:0.8583\n",
            "SSIM for 0849.png:0.8538\n",
            "SSIM for 0850.png:0.9039\n",
            "SSIM for 0851.png:0.9084\n",
            "SSIM for 0852.png:0.8146\n",
            "SSIM for 0853.png:0.9268\n",
            "SSIM for 0854.png:0.8799\n",
            "SSIM for 0855.png:0.9060\n",
            "SSIM for 0856.png:0.7870\n",
            "SSIM for 0857.png:0.9474\n",
            "SSIM for 0858.png:0.8615\n",
            "SSIM for 0859.png:0.8493\n",
            "SSIM for 0860.png:0.8015\n",
            "SSIM for 0861.png:0.8319\n",
            "SSIM for 0862.png:0.9329\n",
            "SSIM for 0863.png:0.9468\n",
            "SSIM for 0864.png:0.9135\n",
            "SSIM for 0865.png:0.8900\n",
            "SSIM for 0866.png:0.8948\n",
            "SSIM for 0867.png:0.8964\n",
            "SSIM for 0868.png:0.9749\n",
            "SSIM for 0869.png:0.8907\n",
            "SSIM for 0870.png:0.9093\n",
            "SSIM for 0871.png:0.9345\n",
            "SSIM for 0872.png:0.8489\n",
            "SSIM for 0873.png:0.8555\n",
            "SSIM for 0874.png:0.9028\n",
            "SSIM for 0875.png:0.8083\n",
            "SSIM for 0876.png:0.7761\n",
            "SSIM for 0877.png:0.9675\n",
            "SSIM for 0878.png:0.9382\n",
            "SSIM for 0879.png:0.8953\n",
            "SSIM for 0880.png:0.9559\n",
            "SSIM for 0881.png:0.9018\n",
            "SSIM for 0882.png:0.9552\n",
            "SSIM for 0883.png:0.8771\n",
            "SSIM for 0884.png:0.8620\n",
            "SSIM for 0885.png:0.8080\n",
            "SSIM for 0886.png:0.9419\n",
            "SSIM for 0887.png:0.8683\n",
            "SSIM for 0888.png:0.9282\n",
            "SSIM for 0889.png:0.9163\n",
            "SSIM for 0890.png:0.8815\n",
            "SSIM for 0891.png:0.8566\n",
            "SSIM for 0892.png:0.9222\n",
            "SSIM for 0893.png:0.9241\n",
            "SSIM for 0894.png:0.9174\n",
            "SSIM for 0895.png:0.8081\n",
            "SSIM for 0896.png:0.9657\n",
            "SSIM for 0897.png:0.8576\n",
            "SSIM for 0898.png:0.9461\n",
            "SSIM for 0899.png:0.9130\n",
            "SSIM for 0900.png:0.8744\n",
            "SSIM for image_2365.jpg:0.8281\n",
            "SSIM for image_2366.jpg:0.8805\n",
            "SSIM for image_2367.jpg:0.8653\n",
            "SSIM for image_2368.jpg:0.9070\n",
            "SSIM for image_2369.jpg:0.9506\n",
            "SSIM for image_2371.jpg:0.9516\n",
            "SSIM for image_2372.jpg:0.9419\n",
            "SSIM for image_2373.jpg:0.9270\n",
            "SSIM for image_2374.jpg:0.9053\n",
            "SSIM for image_2375.jpg:0.9242\n",
            "SSIM for image_2377.jpg:0.9745\n",
            "SSIM for image_2379.jpg:0.9215\n",
            "SSIM for image_2380.jpg:0.9685\n",
            "SSIM for image_2381.jpg:0.9187\n",
            "SSIM for image_2383.jpg:0.9572\n",
            "SSIM for image_2384.jpg:0.7944\n",
            "SSIM for image_2388.jpg:0.9426\n",
            "SSIM for image_2389.jpg:0.8947\n",
            "SSIM for image_2390.jpg:0.9319\n",
            "SSIM for image_2393.jpg:0.9349\n",
            "SSIM for image_2394.jpg:0.9251\n",
            "SSIM for image_2395.jpg:0.9381\n",
            "SSIM for image_2396.jpg:0.9257\n",
            "SSIM for image_2397.jpg:0.9190\n",
            "SSIM for image_2398.jpg:0.9609\n",
            "SSIM for image_2399.jpg:0.9703\n",
            "SSIM for image_2400.jpg:0.9062\n",
            "SSIM for image_2402.jpg:0.9315\n",
            "SSIM for image_2403.jpg:0.9103\n",
            "SSIM for image_2404.jpg:0.9242\n",
            "SSIM for image_2405.jpg:0.9578\n",
            "SSIM for image_2408.jpg:0.9364\n",
            "SSIM for image_2410.jpg:0.9005\n",
            "SSIM for image_2411.jpg:0.9269\n",
            "SSIM for image_2412.jpg:0.9042\n",
            "SSIM for image_2414.jpg:0.9435\n",
            "SSIM for image_2415.jpg:0.8772\n",
            "SSIM for image_2416.jpg:0.9175\n",
            "SSIM for image_2417.jpg:0.9438\n",
            "SSIM for image_2418.jpg:0.9424\n",
            "SSIM for image_2419.jpg:0.9204\n",
            "SSIM for image_2421.jpg:0.9378\n",
            "SSIM for image_2422.jpg:0.9118\n",
            "SSIM for image_2423.jpg:0.8409\n",
            "SSIM for image_2424.jpg:0.9377\n",
            "SSIM for image_2425.jpg:0.8787\n",
            "SSIM for image_2427.jpg:0.9150\n",
            "SSIM for image_2428.jpg:0.8894\n",
            "SSIM for image_2430.jpg:0.9163\n",
            "SSIM for image_2431.jpg:0.9251\n",
            "SSIM for image_2432.jpg:0.9314\n",
            "SSIM for image_2433.jpg:0.9355\n",
            "SSIM for image_2434.jpg:0.9332\n",
            "SSIM for image_2436.jpg:0.9229\n",
            "SSIM for image_2437.jpg:0.7766\n",
            "SSIM for image_2438.jpg:0.9380\n",
            "SSIM for image_2439.jpg:0.9120\n",
            "SSIM for image_2441.jpg:0.8538\n",
            "SSIM for image_2443.jpg:0.9422\n",
            "SSIM for image_2447.jpg:0.9029\n",
            "SSIM for image_2448.jpg:0.9070\n",
            "SSIM for image_2450.jpg:0.9212\n",
            "SSIM for image_2451.jpg:0.9307\n",
            "SSIM for image_2452.jpg:0.9319\n",
            "SSIM for image_2453.jpg:0.9200\n",
            "SSIM for image_2454.jpg:0.9573\n",
            "SSIM for image_2456.jpg:0.9286\n",
            "SSIM for image_2459.jpg:0.8756\n",
            "SSIM for image_2460.jpg:0.8046\n",
            "SSIM for image_2461.jpg:0.7479\n",
            "SSIM for image_2463.jpg:0.8180\n",
            "SSIM for image_2464.jpg:0.9347\n",
            "SSIM for image_2466.jpg:0.8999\n",
            "SSIM for image_2467.jpg:0.8466\n",
            "SSIM for image_2468.jpg:0.8931\n",
            "SSIM for image_2470.jpg:0.9344\n",
            "SSIM for image_2471.jpg:0.9569\n",
            "SSIM for image_2472.jpg:0.9453\n",
            "SSIM for image_2473.jpg:0.9323\n",
            "SSIM for image_2474.jpg:0.8709\n",
            "SSIM for image_2475.jpg:0.8561\n",
            "SSIM for image_2477.jpg:0.8156\n",
            "SSIM for image_2478.jpg:0.9337\n",
            "SSIM for image_2480.jpg:0.8066\n",
            "SSIM for image_2481.jpg:0.9302\n",
            "SSIM for image_2483.jpg:0.9048\n",
            "SSIM for image_2485.jpg:0.9455\n",
            "SSIM for image_2486.jpg:0.9195\n",
            "SSIM for image_2487.jpg:0.9630\n",
            "SSIM for image_2488.jpg:0.9192\n",
            "SSIM for image_2489.jpg:0.9634\n",
            "SSIM for image_2490.jpg:0.8772\n",
            "SSIM for image_2492.jpg:0.9523\n",
            "SSIM for image_2493.jpg:0.8514\n",
            "SSIM for image_2494.jpg:0.9270\n",
            "SSIM for image_2495.jpg:0.9266\n",
            "SSIM for image_2497.jpg:0.8517\n",
            "SSIM for image_2498.jpg:0.9476\n",
            "SSIM for image_2499.jpg:0.9110\n",
            "SSIM for image_2500.jpg:0.9247\n",
            "\n",
            "Average SSIM:0.9023\n"
          ]
        }
      ]
    }
  ]
}